<!DOCTYPE html>
<html lang="en">

  <head>
      <title>Brian Keating</title>
      <link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,600italic,700italic,400,600,700' rel='stylesheet' type='text/css' />
      <link href='http://fonts.googleapis.com/css?family=Merriweather:300' rel='stylesheet' type='text/css'/>
      <link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:200,400,700' rel='stylesheet' type='text/css'/>
      <link rel="stylesheet" type="text/css" href="/theme/css/icons.css"/>
      <link rel="stylesheet" type="text/css" href="/theme/css/styles.css"/>
      <meta charset="utf-8" />
  </head>

  <body id="index">
    <!-- header -->
    <header class="siteheader">
      <!-- site image -->
        <div class= "siteimage">
          <a class="nodec" href=images/headshot.jpg>
            <img width="200" height="200" src=images/headshot.jpg>
          </a>
        </div>

      <div class = "sitebanner">
        <h1><a class="sitetitle nodec" href="">Brian Keating</a></h1>
        <h3 class ="sitesubtitle">Compter Vision Engineer</h3>
        <!-- nav -->
        <nav class="menu">
          <ul>
            <!-- menu items-->
              <li><a class="nodec" href="/">home</a></li>
              <li><a class="nodec" href="/blog.html">blog</a></li>
              <li><a class="nodec" href="/beer.html">beer</a></li>
            <!--pages-->
            <!-- services icons -->
              <li><a class="nodec icon-mail-alt" href="mailto:brikeats@gmail.com"></a></li>
              <li><a class="nodec icon-github" href="https://github.com/brikeats"></a></li>
          </ul>
        </nav>
      </div> <!-- sitebanner -->
    </header>

    <!-- content -->

<section class="content">

  <h3 class="posttitle">
    <a class="nodec" href="/progressive_gans.html" rel="bookmark" title="Permalink to Progressive GANs">
      Progressive GANs
    </a>
  </h3>

  <div class="postinfo">
    <p class="published" title="2017-12-23T00:00:00-08:00">
      Sat 23 December 2017
    </p>

  </div><!-- .postinfo -->

  <div class="article">
    <p>Generative models, <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network">GANs</a> in particular, have been all the rage in the computer vision and deep learning communities for a few years now. These models are notoriously difficult to train, and it has been challenging to scale them up to larger (i.e., higher-res) images.</p>
<p>Nvidia has a <a href="https://arxiv.org/pdf/1710.10196.pdf">recent paper</a> which effectively scales GANs up to 1024x1024 images. The basic idea is quite simple: start by training a generator and discriminator on very low resolution (2x2) images, and, as training progresses, add layers and increase the spatial resolution. Thus, the generator and the descriminator learn large-scale image structures first, then medium-scale, then fine-scale. This approach, dubbed "Progressive GANs", has a stabilizing influence on training, since the model doesn't need to learn all scales at once. They have super-cool visualizations of generated celebrity headshots:</p>
<h1></h1>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/XOxxPcy5Gr4?rel=0" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe></p>
<h1></h1>
<p>To play around with this, I cloned <a href="https://github.com/tkarras/progressive_growing_of_gans">the repo</a> and downloaded the trained model binary <code>100-celeb-hq-1024x1024-ours</code> <a href="https://drive.google.com/open?id=0B4qLcYyJmiz0WUI5b3dBTWkxQU0">from google drive</a>. The models are implemented in Theano, which I haven't used before (and which is <a href="https://groups.google.com/forum/#!msg/theano-users/7Poq8BZutbY/rNCIfvAEAwAJ">no longer being developed</a>). I wrote a notebook to use the generative model sample random celebrity faces -- input a random 512-D feature vector and it produces a celebrity face. The notebook can be viewed <a href="/notebooks/generate-celeb-samples.html">here</a> or downloaded <a href="/notebooks/generate-celeb-samples.ipynb">here</a>. The model is pretty resource hungry -- running single-threaded on my laptop, it takes 40 seconds and ~3GB of RAM to produce a single image.</p>
<p>About half of the samples looked realistic...</p>
<p><img alt="realistic head shot of handsome man" src="/images/very_good.png" /></p>
<p><img alt="realistic head shot that looks vaguely like fat elvis" src="/images/good.png" /></p>
<p>...or almost right:</p>
<p><img alt="realistic head shot with half a pair of glasses" src="/images/disappearing_glasses.png" /></p>
<p><img alt="lady with horrifying mole on head" src="/images/moley-mole-mole.png" /></p>
<p>However, about 1/3 of the images were unnerving...</p>
<p><img alt="woman who is too happy" src="/images/happy-insane.png" /></p>
<p><img alt="goat-woman hybrid with steve buscemi teeth" src="/images/bearded_woman.png" /></p>
<p>...and some are downright disturbing:</p>
<p><img alt="nightmarish image of middle-aged man with messed up mouth" src="/images/nightmare.png" /></p>
<p><img alt="disturbing pic of young man with half-bald head that has a seam with green boogers coming out" src="/images/nightmare2.png" /></p>
<p><img alt="otherworldly, arty-looking picture of a ghost" src="/images/nightmare3.png" /></p>
<p>The main purpose of this paper is to demonstrate that, with a clever multiscale training schedule, standard GANs can produce realistic images at high resolution. The most impressive results are achieved on a carefully curated dataset with a limited domain -- the celebrity dataset is carefully preprocessed using "classical" image processing so that the faces are aligned and the background is just-so. </p>
<p>I think it's interesting to consider the failure modes of this model, in particular the image with disappearing glasses (3rd from the top). Many of the weird artifacts in these images are due to the fact that the model has no notion of the <em>objectness</em> of the pixel patterns that it sees. Mapping a real-valued feature vector to a texture, a color, lines, makes sense. Continuously changing the pose of the head, the hair/skin color, or the quality of the lighting is sensible; likewise one can imagine morphing the color and texture of the background. However, continuously changing model output from "no-glasses-in-image" to "has-glasses-in-image" makes less sense. In theory the model can learn discrete decision boundaries, but the architecture is not set up to explicitly capture the fact that pixel patterns are generated by discrete objects with properties. There are analogous problems with generative language models: individual phrases and clauses are okay, but the model has trouble combining them into a sensible whole.</p>
<p>The stabilizing influence of the multiscale training procedure is an important contribution to the GAN literature. However, it seems like confabulating more complex scenes requires a more sophisticated representation of the latent space than is afforded by a 512-dimensional vector. A better approach might be as simple as encouraging a more interpretable latent representation (<a href="https://arxiv.org/abs/1606.03657">as in infoGANs</a>), or may require a more explicit "inverse rendering approach" (as in <a href="https://www.youtube.com/watch?v=rTawFwUvnLE">Geoff Hinton's capsules</a>).</p>
  </div><!-- .content -->

</section>


    <!-- footer -->
    <footer>
      <p>
        Â© Brian Keating, license <a href=""> </a>
        unless otherwise noted.
        Generated by <a href= "http://docs.getpelican.com/">Pelican</a> with
        <a href="http://github.com/porterjamesj/crowsfoot">crowsfoot</a> theme.
      </p>
    </footer>
  </body>
</html>